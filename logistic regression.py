# -*- coding: utf-8 -*-
"""Assignment1_20200373_20200108.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WLE8IBn6LMQ18aRvf851uW29NRd1dJ0M
"""

import numpy as np

import pandas as pd

#Load MNIST dataset.
from keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

#Subseting data to use only class 0 and class1.
train_condition = np.where((y_train == 0) | (y_train == 1))
x_train = x_train[train_condition]
y_train = y_train[train_condition]
test_condition = np.where((y_test == 0) | (y_test == 1))
x_test = x_test[test_condition]
y_test = y_test[test_condition]

#Standardize dataset
mean = np.mean(x_train)
std = np.std(x_train)
x_train_std = (x_train - mean) / std
x_test_std = (x_test - mean) / std

# determine num. of folds and shuffling data
folds_num = 10
fold_size = len(x_train_std) // folds_num
np.random.seed(30)
shuffle_indices = np.random.permutation(len(x_train_std))
x_train_std = x_train_std[shuffle_indices]
y_train = y_train[shuffle_indices]

#Implement Logistic Regression with different values for learning rate
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def predict(x, w, b):
    z = np.dot(x, w) + b
    return sigmoid(z)

def accuracy(y_true, y_pred):
    y_pred = np.round(y_pred)
    return np.mean(y_true == y_pred)

def logistic_regression(x_train, y_train, x_valid, y_valid, learning_rate, num_iterations):
    m = len(x_train)
    n = x_train.shape[1] * x_train.shape[2]
    w = np.zeros(n)
    b = 0
    x_train_flat = x_train.reshape(m, -1)
    for i in range(num_iterations):
        z = np.dot(x_train_flat, w) + b
        a = sigmoid(z)
        dz = a - y_train
        dw = np.dot(x_train_flat.T, dz) / m
        db = np.sum(dz) / m
        w -= learning_rate * dw
        b -= learning_rate * db

    x_valid_flat = x_valid.reshape(len(x_valid), -1)
    y_valid_pred = predict(x_valid_flat, w, b)
    valid_accuracy = accuracy(y_valid, y_valid_pred)
    return valid_accuracy

# different learning rates
learning_rates = [0.001, 0.01, 0.1, 1]
#array to store accuracies
accuracies = []
for lr in learning_rates:
    fold_accuracies = []
    #Divide data into training and validation set using 10-fold cross validation method
    for fold in range(folds_num):
        start_value = fold * fold_size
        end_value = (fold + 1 ) * fold_size
        x_fold_valid = x_train_std[start_value:end_value]
        y_fold_valid = y_train[start_value:end_value]
        x_train_fold = np.concatenate((x_train_std[:start_value],x_train_std[end_value:]),axis=0)
        y_train_fold = np.concatenate((y_train[:start_value],y_train[end_value:]),axis=0)
        fold_accuracy = logistic_regression(x_train_fold, y_train_fold, x_fold_valid, y_fold_valid, lr, 1000)
        fold_accuracies.append(fold_accuracy)
    # mean accuracy for all k
    mean_accuracy = np.mean(fold_accuracies)
    accuracies.append(mean_accuracy)
    print('Learning rate:', lr, 'Accuracy:', mean_accuracy)